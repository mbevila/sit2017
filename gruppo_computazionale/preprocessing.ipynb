{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ho creato un pacchetto (`process.py`, in questa cartella) che contiene una funzione per convertire il corpus in un formato tale da contenere solo i dati che ci servono e una classe iterabile che consente di non caricare tutto il corpus in RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from preprocessing import parse_paisa, CorpusIterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `parse_paisa()`\n",
    "Se per esempio volessimo estrarre solo i token grezzi basta utilizzare la funzione in questo modo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parse_paisa(\n",
    "    source_fn = \"test.txt\", #sorgente\n",
    "    target_fn = \"test_processed.txt\", #destinazione\n",
    "    cols = [1], #colonne da cui estrarre i dati\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davide Guglielmini , finito agli arresti domiciliari assieme ad altre quattro persone , hanno presentato alla Procura una documentazione composta da planimetrie e documenti nella quale si spiega che la situazione dei bagni e dei privè sarebbe radicalmente cambiata ( ... ) i bagni non si trovano più all' interno del locale , ma fuori ; anche la zona adibita a privè è stata modificata . \n",
      "\n",
      "Due elementi importanti , perché era appunto nei bagni e nel privè che i clienti , vip e persone comuni , consumavano cocaina , come documentato dalle « cimici » piazzate nel 2007 dalla polizia ( guarda il video ) . \n",
      "\n",
      "Le modifiche avrebbero eliminato le zone « nascoste » \n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"test_processed.txt\") as r:\n",
    "    for _, line in zip(range(3), r):\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se invece interessa aggregare più livelli di annotazione, basta passare nell'argomento `cols` una lista contenente gli indici delle colonne che nel file originale contenevano i livelli di annotazione.\n",
    "Es:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parse_paisa(\n",
    "    source_fn = \"test.txt\", \n",
    "    target_fn = \"test_processed2.txt\", \n",
    "    cols = [1, 2, 3], #1=token, 2=lemma, 3=POS a bassa granularità\n",
    "    joiner = \"|\", #carattere utilizzato per aggregare i dati\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davide|Davide|S Guglielmini|Guglielmini|S ,|,|F finito|finire|V agli|al|E arresti|arresto|S domiciliari|domiciliare|A assieme|assieme|B ad|ad|E altre|altro|D quattro|quattro|N persone|persona|S ,|,|F hanno|avere|V presentato|presentare|V alla|al|E Procura|Procura|S una|una|R documentazione|documentazione|S composta|comporre|V da|da|E planimetrie|planimetria|S e|e|C documenti|documento|S nella|in|E quale|quale|P si|si|P spiega|spiegare|V che|che|C la|il|R situazione|situazione|S dei|di|E bagni|bagno|S e|e|C dei|di|E privè|privè|S sarebbe|essere|V radicalmente|radicalmente|B cambiata|cambiare|V (|(|F ...|...|F )|)|F i|il|R bagni|bagno|S non|non|B si|si|P trovano|trovare|V più|più|B all'|al|E interno|interno|S del|di|E locale|locale|S ,|,|F ma|ma|C fuori|fuori|B ;|;|F anche|anche|B la|il|R zona|zona|S adibita|adibire|V a|a|E privè|privè|S è|essere|V stata|essere|V modificata|modificare|V .|.|F \n",
      "\n",
      "Due|due|N elementi|elemento|S importanti|importante|A ,|,|F perché|perché|C era|essere|V appunto|appunto|B nei|in|E bagni|bagno|S e|e|C nel|in|E privè|privè|S che|che|C i|il|R clienti|cliente|S ,|,|F vip|vip|S e|e|C persone|persona|S comuni|comune|A ,|,|F consumavano|consumare|V cocaina|cocaina|S ,|,|F come|come|C documentato|documentare|V dalle|da|E «|«|F cimici|cimice|S »|»|F piazzate|piazzato|A nel|in|E 2007|2007|N dalla|da|E polizia|polizia|S (|(|F guarda|guardare|V il|il|R video|video|S )|)|F .|.|F \n",
      "\n",
      "Le|il|R modifiche|modifica|S avrebbero|avere|V eliminato|eliminare|V le|il|R zone|zona|S «|«|F nascoste|nascosto|A »|»|F \n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"test_processed2.txt\") as r:\n",
    "    for _, line in zip(range(3), r):\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `CorpusIterator()`\n",
    "I files convertiti in questo modo possono essere letti dalla classe `CorpusIterator`. L'ho documentata abbastanza estensivamente (`help(CorpusIterator)`).\n",
    "Due esempi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['davide', 'guglielmini', 'finito', 'agli', 'arresti', 'domiciliari', 'assieme', 'ad', 'altre', 'quattro', 'persone', 'hanno', 'presentato', 'alla', 'procura', 'una', 'documentazione', 'composta', 'da', 'planimetrie', 'e', 'documenti', 'nella', 'quale', 'si', 'spiega', 'che', 'la', 'situazione', 'dei', 'bagni', 'e', 'dei', 'privè', 'sarebbe', 'radicalmente', 'cambiata', 'i', 'bagni', 'non', 'si', 'trovano', 'più', 'all', 'interno', 'del', 'locale', 'ma', 'fuori', 'anche', 'la', 'zona', 'adibita', 'a', 'privè', 'è', 'stata', 'modificata']\n",
      "\n",
      "['due', 'elementi', 'importanti', 'perché', 'era', 'appunto', 'nei', 'bagni', 'e', 'nel', 'privè', 'che', 'i', 'clienti', 'vip', 'e', 'persone', 'comuni', 'consumavano', 'cocaina', 'come', 'documentato', 'dalle', 'cimici', 'piazzate', 'nel', 'dalla', 'polizia', 'guarda', 'il', 'video']\n",
      "\n",
      "['le', 'modifiche', 'avrebbero', 'eliminato', 'le', 'zone', 'nascoste']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentences = CorpusIterator(\n",
    "    fn = \"test_processed.txt\",\n",
    "    remove_stopwords = False,\n",
    ")\n",
    "for _, sentence in zip(range(3), sentences):\n",
    "    print(sentence)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qui invece il reader funziona su un corpus dove sono aggregati i livelli token, lemma e POS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['davide|davide|s', 'guglielmini|guglielmini|s', 'finito|finire|v', 'arresti|arresto|s', 'domiciliari|domiciliare|a', 'assieme|assieme|b', 'altre|altro|d', 'quattro|quattro|n', 'persone|persona|s', 'presentato|presentare|v', 'procura|procura|s', 'documentazione|documentazione|s', 'composta|comporre|v', 'planimetrie|planimetria|s', 'documenti|documento|s', 'spiega|spiegare|v', 'situazione|situazione|s', 'bagni|bagno|s', 'privè|privè|s', 'radicalmente|radicalmente|b', 'cambiata|cambiare|v', 'bagni|bagno|s', 'trovano|trovare|v', 'interno|interno|s', 'locale|locale|s', 'fuori|fuori|b', 'zona|zona|s', 'adibita|adibire|v', 'privè|privè|s', 'stata|essere|v', 'modificata|modificare|v']\n",
      "\n",
      "['due|due|n', 'elementi|elemento|s', 'importanti|importante|a', 'appunto|appunto|b', 'bagni|bagno|s', 'privè|privè|s', 'clienti|cliente|s', 'vip|vip|s', 'persone|persona|s', 'comuni|comune|a', 'consumavano|consumare|v', 'cocaina|cocaina|s', 'documentato|documentare|v', 'cimici|cimice|s', 'piazzate|piazzato|a', 'polizia|polizia|s', 'guarda|guardare|v', 'video|video|s']\n",
      "\n",
      "['modifiche|modifica|s', 'eliminato|eliminare|v', 'zone|zona|s', 'nascoste|nascosto|a']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentences2 = CorpusIterator(\n",
    "    fn = \"test_processed2.txt\",\n",
    "    joiner = \"|\", #argomento di default\n",
    "    stopword_index = 0, #altro argomento di default\n",
    ")\n",
    "for _, sentence in zip(range(3), sentences2):\n",
    "    print(sentence)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infine, gli oggetti corpus `CorpusIterator` possono essere passati direttamente a `Word2Vec`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensioni modello: (2931, 20)\n"
     ]
    }
   ],
   "source": [
    "model = Word2Vec(\n",
    "    sentences, \n",
    "    size=20, \n",
    "    window=5, \n",
    "    min_count=1, #giusto perché il corpus test è minuscolo\n",
    "    iter=100,\n",
    ")\n",
    "print(\"Dimensioni modello:\", model.syn0.shape)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [nlp]",
   "language": "python",
   "name": "Python [nlp]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
